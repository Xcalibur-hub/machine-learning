{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOfmvopiufichIUTd5XmT2R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Xcalibur-hub/machine-learning/blob/main/Heat_wave_detection_system.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lO7b267EhE1m"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sn\n",
        "import missingno\n",
        "import tensorflow as tf\n",
        "from datetime import datetime\n",
        "import plotly.express as px\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, InputLayer\n",
        "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler, ModelCheckpoint\n",
        "\n",
        "# Load and prepare the data\n",
        "def load_data(file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "    df['date'] = pd.to_datetime(df['date'])\n",
        "    return df\n",
        "\n",
        "# Visualize missing values\n",
        "def visualize_missing_data(df):\n",
        "    missingno.bar(df)\n",
        "    plt.show()\n",
        "\n",
        "# Clean the DataFrame\n",
        "def clean_data(df):\n",
        "    # Filter dates and drop irrelevant columns\n",
        "    df = df[df['date'] >= '2020-01-01']\n",
        "    df.drop(columns=['capital', 'capital_lat', 'capital_lng', 'iso2', 'iso3',\n",
        "                    'population', 'native_name', 'continent', 'region',\n",
        "                    'sunshine_total_min', 'Unnamed: 0', 'snow_depth_mm',\n",
        "                    'peak_wind_gust_kmh', 'station_id'], inplace=True)\n",
        "    return df\n",
        "\n",
        "# Add date features and visualize temperature trends\n",
        "def enhance_and_visualize(df):\n",
        "    df['year'] = df['date'].dt.year\n",
        "    df['month'] = df['date'].dt.month\n",
        "    df['day'] = df['date'].dt.day\n",
        "\n",
        "    # Plot max temperature over time\n",
        "    fig = px.line(df, x='date', y='max_temp_c', color='city_name', title='Max Temp Over Time')\n",
        "    fig.show()\n",
        "\n",
        "# Handle missing values\n",
        "def handle_missing_values(df):\n",
        "    df.fillna(method='bfill', inplace=True)\n",
        "    df.fillna(0, inplace=True)\n",
        "    return df\n",
        "\n",
        "# Feature engineering\n",
        "def feature_engineering(df):\n",
        "    df['sin_month'] = np.sin(2 * np.pi * df['month'] / 12)\n",
        "    df['cos_month'] = np.cos(2 * np.pi * df['month'] / 12)\n",
        "    df['sin_day'] = np.sin(2 * np.pi * df['day'] / 31)\n",
        "    df['cos_day'] = np.cos(2 * np.pi * df['day'] / 31)\n",
        "\n",
        "    # Additional feature calculations\n",
        "    df['min_plus_avg'] = df['min_temp_c'] + df['avg_temp_c']\n",
        "    # More features can be added as needed...\n",
        "\n",
        "    return df\n",
        "\n",
        "# Scale the features\n",
        "def scale_features(df):\n",
        "    scaler = StandardScaler()\n",
        "    scaled_features = scaler.fit_transform(df.select_dtypes(include=['float', 'int']))\n",
        "    return pd.DataFrame(scaled_features, columns=df.select_dtypes(include=['float', 'int']).columns)\n",
        "\n",
        "# Prepare data for the model\n",
        "def prepare_data(df, window_size=14):\n",
        "    X, y = [], []\n",
        "    df_as_np = df.to_numpy()\n",
        "    for i in range(len(df_as_np) - window_size):\n",
        "        X.append(df_as_np[i:i + window_size])\n",
        "        y.append(df_as_np[i + window_size, df.columns.get_loc('max_temp_c')])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# Build and train the LSTM model\n",
        "def build_and_train_model(X_train, y_train):\n",
        "    model = Sequential([\n",
        "        InputLayer(input_shape=(X_train.shape[1], X_train.shape[2])),\n",
        "        LSTM(64, activation='relu'),\n",
        "        Dense(1)\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "    # Set up callbacks\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "    cp = ModelCheckpoint('best_model.h5', save_best_only=True)\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(X_train, y_train, validation_split=0.2, epochs=50, batch_size=32,\n",
        "                        callbacks=[early_stopping, cp], verbose=1)\n",
        "    return model\n",
        "\n",
        "# Evaluate model\n",
        "def evaluate_model(model, X_val, y_val):\n",
        "    y_val_pred = model.predict(X_val)\n",
        "    mse = mean_squared_error(y_val, y_val_pred)\n",
        "    r2 = r2_score(y_val, y_val_pred)\n",
        "    return mse, r2\n",
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    # Load data\n",
        "    file_path = \"/content/drive/MyDrive/heat-wave-data/data/ea.csv\"\n",
        "    df = load_data(file_path)\n",
        "\n",
        "    # Visualize missing data\n",
        "    visualize_missing_data(df)\n",
        "\n",
        "    # Clean and prepare data\n",
        "    df = clean_data(df)\n",
        "    df = handle_missing_values(df)\n",
        "    df = feature_engineering(df)\n",
        "\n",
        "    # Scale features\n",
        "    scaled_df = scale_features(df)\n",
        "\n",
        "    # Prepare X and y\n",
        "    X, y = prepare_data(scaled_df)\n",
        "\n",
        "    # Split data into training and validation sets\n",
        "    X_train, X_val = X[:4500], X[4500:]\n",
        "    y_train, y_val = y[:4500], y[4500:]\n",
        "\n",
        "    # Build and train the model\n",
        "    model = build_and_train_model(X_train, y_train)\n",
        "\n",
        "    # Evaluate the model\n",
        "    mse, r2 = evaluate_model(model, X_val, y_val)\n",
        "    print(f'MSE: {mse}, R-squared: {r2}')\n"
      ]
    }
  ]
}